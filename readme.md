# Transformers from scratch

*In this repo an implementation of a transformer decoder will be implemented from scratch, from tokenization to pretraining of the model.*


# Overview

The project aims to pretrain a small transformer from a corpus dataset to be defined yet.

# Requirements

- Pytorch (CUDA is preferred)

